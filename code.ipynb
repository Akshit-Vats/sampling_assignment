{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780e17da-d4af-4fa4-81e4-3034a6225716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Table (%):\n",
      "\n",
      "   Sampling1 Sampling2 Sampling3 Sampling4 Sampling5\n",
      "M1     90.97      91.7     91.28     84.28     93.67\n",
      "M2     99.69     97.82     99.38     98.25     100.0\n",
      "M3     100.0     100.0     100.0     100.0     100.0\n",
      "M4     98.13     99.13      97.2     97.82     98.69\n",
      "M5     98.13     96.07     96.88     97.38     98.25\n",
      "\n",
      "Best Sampling Technique per Model:\n",
      "\n",
      "M1: Sampling5 (93.67%)\n",
      "M2: Sampling5 (100.0%)\n",
      "M3: Sampling1 (100.0%)\n",
      "M4: Sampling2 (99.13%)\n",
      "M5: Sampling5 (98.25%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. IMPORT LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "# 2. LOAD DATASET\n",
    "\n",
    "df = pd.read_csv(\"Creditcard_data.csv\")\n",
    "\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "\n",
    "# 3. BALANCE THE DATASET\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_bal, y_bal = ros.fit_resample(X, y)\n",
    "\n",
    "balanced_df = pd.concat([X_bal, y_bal], axis=1)\n",
    "\n",
    "\n",
    "# 4. DEFINE SAMPLING TECHNIQUES\n",
    "\n",
    "\n",
    "def simple_random_sampling(data, size=0.7):\n",
    "    return data.sample(frac=size, random_state=42)\n",
    "\n",
    "def systematic_sampling(data, step=2):\n",
    "    return data.iloc[::step, :]\n",
    "\n",
    "def stratified_sampling(data, size=0.7):\n",
    "    X = data.drop(\"Class\", axis=1)\n",
    "    y = data[\"Class\"]\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        X, y, train_size=size, stratify=y, random_state=42\n",
    "    )\n",
    "    return pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "def cluster_sampling(data, n_clusters=10):\n",
    "    data = data.copy()\n",
    "    data[\"cluster\"] = pd.qcut(data.index, n_clusters, labels=False)\n",
    "    clusters = np.random.choice(data[\"cluster\"].unique(), size=5, replace=False)\n",
    "    sampled = data[data[\"cluster\"].isin(clusters)]\n",
    "    return sampled.drop(\"cluster\", axis=1)\n",
    "\n",
    "def bootstrap_sampling(data):\n",
    "    return data.sample(frac=1, replace=True, random_state=42)\n",
    "\n",
    "sampling_methods = {\n",
    "    \"Sampling1\": simple_random_sampling,\n",
    "    \"Sampling2\": systematic_sampling,\n",
    "    \"Sampling3\": stratified_sampling,\n",
    "    \"Sampling4\": cluster_sampling,\n",
    "    \"Sampling5\": bootstrap_sampling\n",
    "}\n",
    "\n",
    "# 5. DEFINE ML MODELS\n",
    "\n",
    "models = {\n",
    "    \"M1\": LogisticRegression(max_iter=1000),\n",
    "    \"M2\": DecisionTreeClassifier(),\n",
    "    \"M3\": RandomForestClassifier(n_estimators=100),\n",
    "    \"M4\": SVC(),\n",
    "    \"M5\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "# 6. RUN EXPERIMENTS\n",
    "\n",
    "results = pd.DataFrame(index=models.keys(), columns=sampling_methods.keys())\n",
    "\n",
    "for samp_name, samp_func in sampling_methods.items():\n",
    "    sampled_data = samp_func(balanced_df)\n",
    "\n",
    "    X_s = sampled_data.drop(\"Class\", axis=1)\n",
    "    y_s = sampled_data[\"Class\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_s, y_s, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        results.loc[model_name, samp_name] = round(acc * 100, 2)\n",
    "\n",
    "\n",
    "# 7. DISPLAY RESULTS\n",
    "\n",
    "print(\"\\nAccuracy Table (%):\\n\")\n",
    "print(results)\n",
    "\n",
    "\n",
    "# 8. BEST SAMPLING PER MODEL\n",
    "\n",
    "print(\"\\nBest Sampling Technique per Model:\\n\")\n",
    "for model in results.index:\n",
    "    best_sampling = results.loc[model].astype(float).idxmax()\n",
    "    best_acc = results.loc[model].astype(float).max()\n",
    "    print(f\"{model}: {best_sampling} ({best_acc}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf434c17-9272-446b-bdd5-401bfcfb718c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
